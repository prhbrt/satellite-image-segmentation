{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train U-NET.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["nTLAmVJUoLUs","8LFUss2HocvP","wh-03vO-fIrH","Rt-KWMMIfNOd","6IEc__j58Ff6","Bss5hc9Xnoww","_aUfZOu5ntro","vUV-sN0Cnqns","k53EULEm5RMW","cYKh7U4vZ6rM","QvnRsNZiezlJ"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"nTLAmVJUoLUs","colab_type":"text"},"source":["## Imports and settings\n","\n","Change the `patches_path` to a local location if you like, this is a good idea when you are training for a long time and need to access the same file a few times, otherwise, e.g. when only evaluating, the copy-overhead to do so is not worth it."]},{"cell_type":"code","metadata":{"id":"uxdtryUIqrHe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"75a5db83-db7b-4d4d-cd12-55f07270395c","executionInfo":{"status":"ok","timestamp":1566922300931,"user_tz":-120,"elapsed":1059,"user":{"displayName":"Herbert Kruitbosch","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_tNhnYR_ex84Iv2aCpI_dvNfbvNrfPUr9X30V=s64","userId":"17110111165934523596"}}},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0tWXy-DcKkXI","colab":{}},"source":["import re\n","import os\n","import cv2\n","import time\n","import numpy\n","import pickle\n","import numbers\n","import warnings\n","from glob import glob\n","from skimage.io import imread, imsave\n","from scipy.ndimage.measurements import label\n","\n","import matplotlib\n","from matplotlib import pyplot\n","\n","from sklearn.model_selection import train_test_split\n","\n","from keras.optimizers import Adam\n","from keras.models import load_model, Model\n","from keras.layers import *\n","\n","import keras.backend as K\n","import tensorflow as tf\n","from keras.backend.common import epsilon\n","\n","try:\n","  from jupyter_progressbar import ProgressBar\n","except ImportError:\n","  !pip3 install jupyter_progressbar\n","  from jupyter_progressbar import ProgressBar"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IQlPs8Kc-ScL","colab":{}},"source":["# root_path = '/content/gdrive/My Drive/Eye_in_the_sky/' # Leslie\n","\n","root_path = '/content/gdrive/My Drive/Projects/2019/Eye_in_the_sky/' # Herbert\n","\n","image_path = f'{root_path}Training Data/Images'\n","mask_path = f'{root_path}Training Data/Mask Labels'\n","gdrive_patches_path = f'{root_path}Training Data/Patches/v2'\n","results_path = f'{root_path}Results'\n","\n","# models_path = f'{root_path}Training Data/Models'\n","\n","patches_path = gdrive_patches_path\n","\n","# Only if you use the next cell below to copy the patches to this directory.\n","# The copying takes some time, but the data loads approx. 3x faster. This is\n","# particularly good when training.\n","\n","# patches_path = '/content/patches'\n","\n","\n","# How much of the patch should be defined, since parts of the satelite images\n","# are black\n","define_t = 0.9"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yiG99i_xGrml","colab_type":"code","colab":{}},"source":["# !mkdir '{patches_path}'\n","# for sample in ProgressBar(os.listdir(f'{gdrive_patches_path}')):\n","#   !cp '{gdrive_patches_path}/{sample}' '{patches_path}'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"07AAgednIFSX","colab_type":"text"},"source":["## Data\n","\n","Creates train, validation and test split\n","\n","Defines `iter_super_batches` to load multiple filenames at once for trianing, and loads the validation set.\n","\n","Test data is not loaded to save memory during training, but kept seperately to ultimately be able to create a proper test report.\n","\n","Also normalizes the data for the neural network to values between -2 and 2.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8LFUss2HocvP","colab_type":"text"},"source":["### Data splitting\n","\n","Train / test split, done on the basis of the original images, not the patches as they may overlap.\n","\n","Note that I fixed the test and validation set, such that loading (partially) trained models later on can not accidentally overlap train en test+validaiton sets."]},{"cell_type":"code","metadata":{"id":"sqBTJQVwjBJL","colab_type":"code","colab":{}},"source":["# samples will contain the extension-less filenames for the images that have\n","# shapes and shapes that have images.\n","\n","image_filenames = os.listdir(f'{image_path}')\n","mask_filenames = os.listdir(f'{mask_path}')\n","\n","samples = numpy.array(list({\n","    filename[:-4]\n","    for filename in image_filenames\n","    if filename.endswith('.tif')\n","} & {\n","    filename[:-4]\n","    for filename in mask_filenames\n","    if filename.endswith('.tif')\n","}))\n","\n","samples = sorted(samples)\n","\n","train_samples, test_samples = train_test_split(samples, test_size=0.05, random_state = 597213461)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nZG-OBOb3R1G","colab":{}},"source":["train_batches = sum(\n","    (glob(f'{patches_path}/sample-{sample}_batch-*.p3')\n","     for sample in train_samples), \n","    [])\n","\n","test_batches_ = sum(\n","    (glob(f'{patches_path}/sample-{sample}_batch-*.p3')\n","     for sample in test_samples), \n","    [])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8T6p7MGWL6lg","colab_type":"code","colab":{}},"source":["validation_batches = [\n"," f'{patches_path}/sample-S2B1C_20180927_108_32UMC_TOA_10_batch-0.p3',\n"," f'{patches_path}/sample-S2B1C_20180927_108_32UMC_TOA_10_batch-1.p3',\n"," f'{patches_path}/sample-S2B1C_20180927_108_32UMC_TOA_10_batch-2.p3',\n"," f'{patches_path}/sample-S2B1C_20180927_108_32UMC_TOA_10_batch-3.p3',\n"," f'{patches_path}/sample-S2B1C_20180927_108_32UMC_TOA_10_batch-4.p3',\n"," f'{patches_path}/sample-S2B1C_20180927_108_32UMC_TOA_10_batch-5.p3',\n"," f'{patches_path}/sample-S2B1C_20180927_108_32UMC_TOA_10_batch-6.p3',\n"," f'{patches_path}/sample-S2B1C_20180927_108_32UMC_TOA_10_batch-7.p3',\n"," f'{patches_path}/sample-S2B1C_20180927_108_32UMC_TOA_10_batch-8.p3',\n","]\n","test_batches = [\n"," f'{patches_path}/sample-S2A1C_20180912_108_32UNA_TOA_10_batch-0.p3',\n"," f'{patches_path}/sample-S2A1C_20180912_108_32UNA_TOA_10_batch-1.p3',\n"," f'{patches_path}/sample-S2A1C_20180912_108_32UNA_TOA_10_batch-2.p3',\n"," f'{patches_path}/sample-S2A1C_20180912_108_32UNA_TOA_10_batch-3.p3',\n"," f'{patches_path}/sample-S2B1C_20180702_008_31UFV_TOA_10_batch-0.p3',\n"," f'{patches_path}/sample-S2A1C_20180918_051_32ULD_TOA_10_batch-0.p3',\n"," f'{patches_path}/sample-S2A1C_20180918_051_32ULD_TOA_10_batch-1.p3',\n"," f'{patches_path}/sample-S2A1C_20180918_051_32ULD_TOA_10_batch-2.p3',\n"," f'{patches_path}/sample-S2A1C_20180918_051_32ULD_TOA_10_batch-3.p3'\n","]\n","\n","assert set(test_batches + validation_batches) == set(test_batches_), \"Something changed in the test train split, such that these constants are not trustworthy anymore. Rethink/do your train/validation/test data splitting.\"\n","assert len(set(test_batches + validation_batches) & set(train_batches)) == 0, \"Train data overlaps with test or validation data, such that these constants are REALLY not trustworthy anymore. Rethink/do your train/validation/test data splitting.\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wh-03vO-fIrH","colab_type":"text"},"source":["### Helper functions"]},{"cell_type":"code","metadata":{"id":"AzbSJ8xdYikt","colab_type":"code","colab":{}},"source":["# One could also inspect all files, but they are large and opening them takes a\n","# long time. Hence the values were precomputed in the same notebook as where\n","# the patches are created.\n","\n","with open(f'{gdrive_patches_path}/../v2-lengths.p3', 'rb') as f:\n","    lengths = pickle.load(f)\n","\n","def get_n_samples(filename, t):\n","  \"\"\"The `v2-lengths.p3` file contains the number of samples in each patches\n","  file given a threshold of how many pixels are defined. That is, some of the\n","  satelite images are partially black (or undefined). If filename is not a\n","  `str`, returns how many samples in that patches file have at least `t`\n","  defined. If filename is a list (of `str`), returns the sum of samples for\n","  each filename in the list.\"\"\"\n","  \n","  assert type(filename) in {str, list}\n","  if type(filename) == list:\n","    return sum(get_n_samples(filename, t) for filename in filename)\n","  counts = lengths[filename]\n","  keys = [k for k in counts.keys() if k >= t]\n","  if len(keys) == 0:\n","    return 0\n","  return counts[min(keys)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ITMek3Y9Ay0d","colab_type":"code","colab":{}},"source":["# The offsets were defined as the medians in `Estimate mean and stddev`. There were some extreme\n","# outliers, so 5% of the large outliers was neglected at both sides (so 10% in total). Moreover,\n","# Only 1% of the data was used finding the outlier thresholds, since the resolution of the images\n","# are very high and sorting gets very slow.\n","#\n","# Furthermore, values are clipped between -2 and 2, since neural network training is not stable\n","# w.r.t. extreme values.\n","#\n","# This code can take up to a few seconds for larger batches, within the order of maginitude of\n","# loading a batch, or even slower. It might be better to do the preprocessing while creating the\n","# batches, which was originally the plan, but I forgot to do so. This way we could also store\n","# the patch as float32 instead of uint64, halving the space needed and hence halving pickle\n","# loading time.\n","\n","# TODO: move to patch creation\n","\n","\n","def preprocess_input(image):\n","  \"\"\" scales the pixels to have mean 0 and stdev 1 and furthermore, clips them between values -2 and\n","  2, for neural network training\"\"\"\n","  offsets = numpy.array([\n","      1264.06439133,  993.71959535,  879.00178412,  740.15150524,  990.24213408,\n","      1798.24382807, 2154.90345801, 2121.7030217 ,  695.56159991,   11.36244131,\n","      1707.93913123, 1008.18696351])\n","  factors = numpy.array([\n","       92.55388916, 139.58717587, 193.49003888, 319.68365431, 317.27768991,\n","      444.25386892, 565.17997105, 593.66462148, 160.98605446,   2.23359842,\n","      631.6088602 , 520.73160082])\n","\n","  image -= offsets[(numpy.newaxis, ) * (len(image.shape) - 1)]\n","  for i, f in enumerate(factors):\n","      image[..., i] /= f\n","\n","  numpy.clip(image, -2, 2, image)\n","  return image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M-IfyV9Ns9yu","colab_type":"code","colab":{}},"source":["def iter_filenames(filenames, shuffle=True):\n","  \"\"\"Infinitively iterates through the filenames, in an epoch manor, that is all filenames need to be\n","  yielded at least n-1 time to yield another filename for the n-th time. They can either be shuffled,\n","  or each epoch can have the order as `filename`m depending on `shuffle`\"\"\"\n","  \n","  filenames = numpy.array(filenames)\n","  order = numpy.arange(len(filenames))\n","  while True:\n","    if shuffle:\n","      numpy.random.shuffle(order)\n","    for filename in filenames[order]:\n","      yield filename\n","\n","\n","def take(it, n):\n","  \"\"\" Returns the next `n` items from `it`, or less if not available, as a list\"\"\"\n","  # zip ensures the list finishes whe`it` is empty or when `n` are extracted. Moreover,\n","  # range is the first in zip to prevent that `n+1` are extracted while only `n` are returned.\n","  return [x for _, x in zip(range(n), next(it))]\n","\n","\n","def iter_super_batches(filenames, files_at_once=25, shuffle=True, t=0.8, channels=slice(None)):\n","  \"\"\" Yields batches of the samples in `files_at_once` random `filenames`, and only selects\n","  samples with at least `t` pixels defined. The `channels` parameter doesn't work (yet) and should\n","  not be changed.\n","  @param `shuffle` only shuffles the filenames, not the samples themselves\n","                   (Keras'sfit can shuffle the samples).\n","  @yields a tuple of the images and the labels\"\"\"\n","  filenames = iter_filenames(filenames, shuffle=shuffle)\n","  \n","  while True:\n","    batch_filenames = take(filenames, files_at_once)\n","    n = get_n_samples([fn.split('/')[-1] for fn in batch_filenames], t)\n","\n","    XX = numpy.zeros((n, 512, 512, 12), dtype=numpy.float32)\n","    yy = numpy.zeros((n, 512, 512, 1), dtype=numpy.bool)\n","\n","    i = 0\n","    for filename in batch_filenames:\n","      with open(filename, 'rb') as f:\n","        data = pickle.load(f)\n","\n","      d = data['defined'].mean(axis=1).mean(axis=1) > t\n","      X = preprocess_input(data['image'][d, ..., channels].astype(numpy.float32))\n","      y = data['buildings'][..., None][d]\n","\n","      XX[i:i+len(y)] = X\n","      yy[i:i+len(y)] = y\n","\n","      i+=len(y)\n","\n","    yield XX, yy"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rt-KWMMIfNOd","colab_type":"text"},"source":["### Validation data\n","\n","Load all validation data, test data could be loaded in the same manor, but this fills up memory and would force you to train in smaller super batches later on."]},{"cell_type":"code","metadata":{"id":"HpUGEv0Rk4r3","colab_type":"code","colab":{}},"source":["n_validation_samples = sum(\n","    get_n_samples(fn.split('/')[-1], define_t)\n","    for fn in validation_batches)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2JVvuaUAZVh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"85957469-add0-4929-a703-00b92b78d525","executionInfo":{"status":"ok","timestamp":1566922362170,"user_tz":-120,"elapsed":62048,"user":{"displayName":"Herbert Kruitbosch","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_tNhnYR_ex84Iv2aCpI_dvNfbvNrfPUr9X30V=s64","userId":"17110111165934523596"}}},"source":["# Load validation data\n","\n","X_valid = numpy.zeros((n_validation_samples, 512, 512, 12), dtype=numpy.float32)\n","y_valid = numpy.zeros((n_validation_samples, 512, 512, 1), dtype=numpy.bool)\n","\n","\n","t = 0.9\n","i = 0\n","for filename in ProgressBar(validation_batches):\n","  with open(filename, 'rb') as f:\n","    data = pickle.load(f)\n","  d = data['defined'].mean(axis=1).mean(axis=1) > define_t\n","  X = preprocess_input(data['image'].astype(numpy.float32))[d]\n","  y = data['buildings'][..., None][d]\n","\n","  X_valid[i:i+len(y)] = X\n","  y_valid[i:i+len(y)] = y\n","\n","  i+=len(y)\n","\n","  del X, y, d, data"],"execution_count":36,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3450c400ab22437cb5ed2ce95843f7c6","version_minor":0,"version_major":2},"text/plain":["VBox(children=(HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='<b>0</b>s passed', placeholder='0…"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"6IEc__j58Ff6","colab_type":"text"},"source":["### Validation Examples"]},{"cell_type":"code","metadata":{"id":"b4VrI-_cme4J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0,"output_embedded_package_id":"1B8ZfTGAiV9tzHYO6R3TH1tSmDOCkBBTn"},"outputId":"2298a798-354d-4963-bf1c-1ed4593e9e51","executionInfo":{"status":"ok","timestamp":1566922425603,"user_tz":-120,"elapsed":125469,"user":{"displayName":"Herbert Kruitbosch","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_tNhnYR_ex84Iv2aCpI_dvNfbvNrfPUr9X30V=s64","userId":"17110111165934523596"}}},"source":["for x, y, axis in zip(X_valid, y_valid, pyplot.subplots(8, 2, figsize=(25, 100))[1].ravel() ):\n","  rgb = (x[..., [3,2,1]] + 2) / 4\n","  mask = y[..., 1:]\n","  axis.imshow(rgb)\n","  axis.imshow(numpy.dstack([y, numpy.zeros(y.shape), numpy.zeros(y.shape), 0.8 * y]))\n","  \n","pyplot.tight_layout()\n","\n","pyplot.savefig(f'{results_path}/example_training_mask.png')"],"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LPX29FGLBamb"},"source":["## U-net model"]},{"cell_type":"markdown","metadata":{"id":"Bss5hc9Xnoww","colab_type":"text"},"source":["### Model"]},{"cell_type":"code","metadata":{"id":"Kl2dRwvH3aFQ","colab_type":"code","colab":{}},"source":["class UNET(Model):\n","    def __init__(self, n_channels=12, *args, **kwargs):\n","        \"\"\"Copied from https://github.com/zhixuhao/unet/blob/master/model.py\"\"\"\n","        inputs = Input([None, None, n_channels])\n","\n","        nfilters = 16 # in the original architecture, this was 64\n","\n","        conv1 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","        conv1 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","        nfilters *= 2\n","        last_out = pool1\n","\n","        conv2 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(last_out)\n","        conv2 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","        nfilters *= 2\n","        last_out = pool2\n","\n","        conv3 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(last_out)\n","        conv3 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","        nfilters *= 2\n","        last_out = pool3\n","\n","        conv4 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(last_out)\n","        conv4 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","        drop4 = Dropout(rate=0.5)(conv4)\n","        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","        nfilters *= 2\n","        last_out = pool4\n","\n","        conv5 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(last_out)\n","        conv5 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","        drop5 = Dropout(rate=0.5)(conv5)\n","        nfilters //= 2 # // is for integer division, where / is floating point division in Python 3\n","        last_out = drop5\n","\n","        up6 = Conv2D(nfilters, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(last_out))\n","        merge6 = concatenate([drop4,up6], axis = 3)\n","\n","        conv6 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","        conv6 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","        nfilters //= 2\n","        last_out = conv6\n","\n","        up7 = Conv2D(nfilters, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(last_out))\n","        merge7 = concatenate([conv3,up7], axis = 3)\n","        conv7 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","        conv7 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","        nfilters //= 2\n","        last_out = conv7\n","        \n","        up8 = Conv2D(nfilters, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(last_out))\n","        merge8 = concatenate([conv2,up8], axis = 3)\n","        conv8 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","        conv8 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","        nfilters //= 2\n","        last_out = conv8\n","\n","        up9 = Conv2D(nfilters, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(last_out))\n","        merge9 = concatenate([conv1,up9], axis = 3)\n","\n","        conv9 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","        conv9 = Conv2D(nfilters, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","        conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","        conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","        super(UNET, self).__init__(inputs=inputs, outputs=conv10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_aUfZOu5ntro","colab_type":"text"},"source":["### Metrics"]},{"cell_type":"code","metadata":{"id":"vav75-z6_SrC","colab_type":"code","colab":{}},"source":["def precision(target, output, epsilon = 0.000001):\n","  P = output > 0.5\n","  TP = tf.logical_and(P, target > 0)\n","  return (epsilon + K.sum(tf.cast(TP, tf.float32))) / (\n","      epsilon + K.sum(tf.cast(P, tf.float32)))\n","\n","\n","def recall(target, output, epsilon = 0.000001):\n","  P = target > 0\n","  TP = tf.logical_and(P, output > 0.5)\n","  return (epsilon + K.sum(tf.cast(TP, tf.float32))) / (\n","      epsilon + K.sum(tf.cast(P, tf.float32)))\n","\n","\n","def k_min(y_true, y_pred):\n","  return K.min(y_pred)\n","\n","\n","def k_max(y_true, y_pred):\n","  return K.max(y_pred)\n","\n","\n","def k_mean(y_true, y_pred):\n","  return K.mean(y_pred > 0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vUV-sN0Cnqns","colab_type":"text"},"source":["### Loss functions"]},{"cell_type":"code","metadata":{"id":"LvpeToYx_rr4","colab_type":"code","colab":{}},"source":["def _to_tensor(x, dtype):\n","    return tf.convert_to_tensor(x, dtype=dtype)\n","  \n","\n","def normalized_binary_crossentropy(target, output, from_logits=False):\n","    if not from_logits:\n","        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n","        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n","        output = tf.log(output / (1 - output))\n","    \n","    w0 = tf.cast(K.sum(target), tf.float32)\n","    s = K.shape(target)\n","    w1 = tf.cast(s[0] * s[1] * s[2] * s[3], tf.float32) - w0\n","    r = K.sqrt(w0*w0 + w1*w1)\n","    w0, w1 = w0 / r, w1 / r\n","    target2 = tf.cast(target, tf.float32)\n","    w = w0 * (1. - target2) + w1 * target2\n","    \n","    r = tf.nn.sigmoid_cross_entropy_with_logits(\n","        labels=target, logits=output)\n","    return w * r\n","\n","\n","def auto_weighting_binary_crossentropy(target, output, from_logits=False):\n","    if not from_logits:\n","        _epsilon = _to_tensor(epsilon(), output.dtype.base_dtype)\n","        output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n","        output = tf.log(output / (1 - output))\n","    \n","    subsample = tf.cast(tf.logical_or(\n","      tf.less(K.random_uniform(K.shape(target), minval=0, maxval=1), 0.02),\n","      tf.greater(target, 0.5)\n","    ), tf.float32)\n","    \n","    r = tf.nn.sigmoid_cross_entropy_with_logits(\n","        labels=target, logits=output)\n","    return r * subsample / 0.04\n","  \n","\n","def soft_dice_loss(y_true, y_pred, epsilon=1e-6): \n","    ''' \n","    Soft dice loss calculation for arbitrary batch size, number of classes, and number of spatial dimensions.\n","    Assumes the `channels_last` format.\n","  \n","    # Arguments\n","        y_true: b x X x Y( x Z...) x c One hot encoding of ground truth\n","        y_pred: b x X x Y( x Z...) x c Network output, must sum to 1 over c channel (such as after softmax) \n","        epsilon: Used for numerical stability to avoid divide by zero errors\n","    \n","    # References\n","        V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation \n","        https://arxiv.org/abs/1606.04797\n","        More details on Dice loss formulation \n","        https://mediatum.ub.tum.de/doc/1395260/1395260.pdf (page 72)\n","        \n","        Adapted from https://github.com/Lasagne/Recipes/issues/99#issuecomment-347775022\n","    '''\n","    \n","    # skip the batch and class axis for calculating Dice score\n","    axes = tuple(range(1, len(y_pred.shape)-1)) \n","    numerator = 2. * K.sum(y_pred * y_true, axes)\n","    denominator = K.sum(K.square(y_pred) + K.square(y_true), axes)\n","    \n","    return 1 - K.mean(numerator / (denominator + epsilon)) # average over classes and batch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k53EULEm5RMW","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"kb64TmtWrFgl","colab_type":"code","colab":{}},"source":["# Most recent iteration for each date, doesn't work anymore because models were moved.\n","\n","# iterations = dict()\n","# filenames = dict()\n","# for filename in os.listdir(f'{root_path}'):\n","#   match = re.match(r'model-(\\d\\d\\d\\d)\\-(\\d\\d)\\-(\\d\\d)\\-(\\d+)\\.p3', filename)\n","#   if match:\n","#     year, month, day, iteration = map(int, match.groups())\n","#     current_iteration = iterations.get((year, month, day), -1)\n","#     if iteration >= current_iteration:\n","#       iterations[(year, month, day)] = iteration\n","#       filenames[(year, month, day)] = filename\n","\n","# for filename in filenames.values():\n","#   print(filename)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WUwvGgqttAb3","colab_type":"code","colab":{}},"source":["# train_data = iter_super_batches(train_batches, files_at_once=40, shuffle=True, t=0.8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n3-iL_g3xGZN","colab_type":"code","colab":{}},"source":["# if you wish to create a new model\n","\n","# i=-1\n","# model = UNET(n_channels=12)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gphYpI_J2ftw","colab_type":"code","colab":{}},"source":["# if you wish to load an existing model\n","\n","i=0 # load the save after super batch `i`\n","model_filename = f'{root_path}/Models/2019-08-13/model-2019-08-13-{i}.p3'\n","\n","model = load_model(model_filename, {\n","    'UNET': UNET,\n","    'normalized_binary_crossentropy': normalized_binary_crossentropy,\n","    'precision': precision,\n","    'recall': recall,\n","    'k_mean': k_mean,\n","    'k_min': k_min,\n","    'k_max': k_max,\n","    'soft_dice_loss': soft_dice_loss\n","})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JULfoddb01L-","colab":{}},"source":["model.compile(\n","    optimizer = Adam(lr = 0.001),\n","    loss = soft_dice_loss,\n","    metrics = ['accuracy', precision, recall, k_min, k_max, k_mean]\n",")\n","\n","# if you like to train\n","\n","# for i, (X, y) in enumerate(train_data, start=i+1):\n","#   curve = model.fit(\n","#       X, y,\n","#       batch_size=16,\n","#       epochs = 50,\n","#       verbose = 1,\n","#       shuffle = True,\n","#       validation_data = (X_valid, y_valid)\n","#   )\n","#   model.save(f'{root_path}/model-2019-08-13-{i}.p3')\n","#   del X, y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fKqrbI0_ocyk","colab_type":"text"},"source":["## Results"]},{"cell_type":"code","metadata":{"id":"tHI73c5Vkfvp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7a650580-42ce-4549-b64e-376a6e9ecd18","executionInfo":{"status":"ok","timestamp":1566922521434,"user_tz":-120,"elapsed":14151,"user":{"displayName":"Herbert Kruitbosch","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC_tNhnYR_ex84Iv2aCpI_dvNfbvNrfPUr9X30V=s64","userId":"17110111165934523596"}}},"source":["y_pred = model.predict(X_valid, batch_size=8, verbose=1)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["284/284 [==============================] - 13s 46ms/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cYKh7U4vZ6rM","colab_type":"text"},"source":["### Prediction examples\n","\n","Predict on some of the samples."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kIs0X8vJ7dp-","colab":{}},"source":["axes = pyplot.subplots(8, 2, figsize=(25, 100))[1].ravel()\n","\n","\n","for x, y, y_pred_, axis in zip(X_valid, y_valid, y_pred, axes):\n","  rgb = (\n","    0.5 * numpy.ones(x.shape[:2] + (3,)) + \n","    0.5 * (x[..., [3,2,1]] + 2) / 4\n","  )\n","  \n","  nothing = numpy.zeros(y.shape, dtype=numpy.uint8)\n","  mask = numpy.concatenate([\n","      255 * y,\n","      nothing,\n","      255 * (y_pred_ > .5),\n","      100 * y + 100 * (y_pred_ > .5),\n","  ], axis=2).astype(numpy.uint8)\n","  \n","  axis.imshow(rgb)\n","  axis.imshow(mask)\n","  \n","pyplot.tight_layout()\n","\n","pyplot.savefig(f'{results_path}/example_predictions.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qomGtAJaaGkn","colab_type":"text"},"source":["### False predictions\n","\n","For sharability, I want to plot all of the false predicitons in one subplot. Hence I create a list of `plotters` in one cell, which contains functions that given an `axis` plot the false prediction. This way I can create the subplot afterwards, because I'll know how many subplot axes are needed.\n","\n","The image is too big and often won't show :("]},{"cell_type":"markdown","metadata":{"id":"QvnRsNZiezlJ","colab_type":"text"},"source":["#### Helper functions"]},{"cell_type":"code","metadata":{"id":"WypR9NcY2Bae","colab_type":"code","colab":{}},"source":["def connected_component_coordinates(mask):\n","  \"\"\"Returns a list with for each connected component in `mask` a sublist of\n","  the pixel coordinates of that connected component.\"\"\"\n","  labels, n = label(mask)\n","\n","  r = [list() for _ in range(n)]\n","  for y, row in enumerate(labels):\n","    for x, elem in enumerate(row):\n","      if elem > 0:\n","        r[int(elem - 1)].append((x, y))\n","  return r\n","\n","\n","def bbox(coords):\n","  return (\n","      min(x for x, y in coords),\n","      max(x for x, y in coords),\n","      min(y for x, y in coords),\n","      max(y for x, y in coords),\n","  )\n","\n","\n","def find_false_prediction_centers(y_true, y_pred):\n","  \"\"\" Returns (xmin, xmax, ymin, ymax) bounding boxes for predicted\n","  (false positives) and actual (false negatives) connected components that do\n","  not overlap respectively with an actual or a predicted connected component.\n","  \n","  @param `y_true` m x n boolean numpy array of ground truth\n","  @param `y_true` m x n boolean numpy array of ground truth\n","  @return two lists of bounding boxes for the false negatives and false\n","          positives respectively.\"\"\"    \n","  true_positives = set(sum(\n","      connected_component_coordinates(\n","          numpy.minimum(y_true, y_pred)\n","      ), []\n","  ))\n","  \n","  false_positives = [\n","    coords\n","    for coords in connected_component_coordinates(y_pred)\n","    if not any(coord in true_positives for coord in coords)\n","  ]\n","  \n","  false_negatives = [\n","    coords\n","    for coords in connected_component_coordinates(y_true)\n","    if not any(coord in true_positives for coord in coords)\n","  ]\n","  \n","  return list(map(bbox, false_negatives)), list(map(bbox, false_positives))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c6D5SOx2e47f","colab_type":"text"},"source":["#### Calculations"]},{"cell_type":"code","metadata":{"id":"ALsl9yQdvMS7","colab_type":"code","outputId":"ccb57ea4-13f9-4695-e8ea-88e54b9140f5","executionInfo":{"status":"ok","timestamp":1565945624123,"user_tz":-120,"elapsed":343556,"user":{"displayName":"Herbert Kruitbosch","photoUrl":"https://lh5.googleusercontent.com/-mYozEruLhbg/AAAAAAAAAAI/AAAAAAAAAAo/z4ouW0BfK6Y/s64/photo.jpg","userId":"17110111165934523596"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["plotters = []\n","padding = 50\n","\n","for img, t, p in zip(ProgressBar(X_valid), y_valid, y_pred > 0.5):\n","  rgb = (\n","    0.6 * numpy.ones(img.shape[:2] + (3,)) + \n","    0.4 * (img[..., [3,2,1]] + 2) / 4\n","  )\n","  \n","  nothing = numpy.zeros(p.shape, dtype=numpy.uint8)\n","  mask = numpy.concatenate([\n","      255 * t,\n","      nothing,\n","      255 * p,\n","      70 * numpy.maximum(t, p)\n","  ], axis=2).astype(numpy.uint8)\n","  \n","  def plot(rgb, mask):\n","    def p(axis):\n","      axis.imshow(rgb)\n","      axis.imshow(mask)\n","    return p\n","  \n","  plotters.append(plot(rgb, mask))\n","  \n","  false_negatives, false_positives = find_false_prediction_centers(t, p)\n","  \n","  error_types = [[1., 1., 0.]] * len(false_negatives) + [[1., 0., 0.]] *  len(false_positives)\n","  for (x0, x1, y0, y1), color in zip(false_negatives + false_positives, error_types):\n","    if (\n","        y0 < padding or y1 >= t.shape[0] - padding or\n","        x0 < padding or x1 >= t.shape[1] - padding\n","    ):\n","      continue\n","      color[2] = 0.333\n","    \n","    w = max(x1-x0, y1-y0)\n","    wx = max(0, w - x1 + x0) // 2\n","    wy = max(0, w - y1 + y0) // 2\n","    y0 = max(0, y0 - padding - wy)\n","    x0 = max(0, x0 - padding - wx)\n","    region = (slice(y0, y0 + 2*padding + w), slice(x0, x0 + 2*padding + w))\n","    \n","    def plot(rgb, mask, color, w):\n","      def p(axis):\n","        axis.imshow(rgb)\n","        axis.imshow(mask)\n","        \n","        for child in axis.get_children():\n","          if isinstance(child, matplotlib.spines.Spine):\n","            child.set_color(color)\n","            child.set_linewidth(4)\n","          \n","        axis.set_xlim(0, w); axis.set_ylim(0, w)\n","      return p\n","    plotters.append(plot(rgb[region], mask[region], color, w + 2*padding))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7b4d6d10a514c1ba9332ff6998cf41e","version_minor":0,"version_major":2},"text/plain":["VBox(children=(HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='<b>0</b>s passed', placeholder='0…"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"DiMyi8-re85J","colab_type":"text"},"source":["#### Result"]},{"cell_type":"code","metadata":{"id":"muQMtuN-68Vq","colab_type":"code","outputId":"022fcd1a-f1a1-4933-be27-9e2311b743ad","executionInfo":{"status":"ok","timestamp":1565945814223,"user_tz":-120,"elapsed":531449,"user":{"displayName":"Herbert Kruitbosch","photoUrl":"https://lh5.googleusercontent.com/-mYozEruLhbg/AAAAAAAAAAI/AAAAAAAAAAo/z4ouW0BfK6Y/s64/photo.jpg","userId":"17110111165934523596"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1_jfzc9IZTeMLfU1vPWvRFwsVdaHd9mRT"}},"source":["width = 24\n","ncols = 8\n","nrows = int(numpy.ceil(len(plotters) / ncols))\n","nrows_max = min(8, nrows)\n","\n","axes = []\n","figures = []\n","for _ in range(0, nrows, nrows_max):\n","  fig, axes_ = pyplot.subplots(\n","      nrows=nrows_max, ncols=ncols,\n","      figsize=(width, width * nrows_max / ncols)\n","  )\n","  axes.extend(axes_.ravel())\n","  figures.append(fig)\n","\n","for axis in axes:\n","  axis.set_xticks([])\n","  axis.set_yticks([])\n","\n","for axis, plotter in zip(axes, ProgressBar(plotters)):\n","  plotter(axis)\n","\n","for i, fig in enumerate(figures):\n","  fig.tight_layout()\n","  fig.savefig(f'{results_path}/false_predictions_batch-{i}.png')"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}